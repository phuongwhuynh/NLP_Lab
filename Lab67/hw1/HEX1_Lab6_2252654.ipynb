{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home-data-for-ml-course.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c home-data-for-ml-course -p .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"home-data-for-ml-course.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\".\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 80)\n",
      "(1459, 79)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train.drop(columns=['Id'],inplace=True)\n",
    "test.drop(columns=['Id'],inplace=True)\n",
    "\n",
    "#fillna with 0 and None\n",
    "\n",
    "train[train.select_dtypes(include=['number']).columns] = train.select_dtypes(include=['number']).fillna(0)\n",
    "test[test.select_dtypes(include=['number']).columns] = test.select_dtypes(include=['number']).fillna(0)\n",
    "\n",
    "train.select_dtypes(include=['object']).fillna('None', inplace=True)\n",
    "test.select_dtypes(include=['object']).fillna('None', inplace=True)\n",
    "\n",
    "numeric_cols = train.select_dtypes(include=['number']).columns\n",
    "train[numeric_cols] = np.log1p(train[numeric_cols])\n",
    "\n",
    "numeric_cols = test.select_dtypes(include=['number']).columns\n",
    "test[numeric_cols] = np.log1p(test[numeric_cols])\n",
    "\n",
    "print(train.shape) \n",
    "print(test.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding for categorical columns\n",
    "train = pd.get_dummies(train).astype(float)\n",
    "test = pd.get_dummies(test).astype(float)\n",
    "X_train = train.drop(columns=['SalePrice'])\n",
    "y_train = train['SalePrice']  \n",
    "\n",
    "X_train, X_test = X_train.align(test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_test = X_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 287)\n",
      "(1459, 287)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)  \n",
    "print(X_test.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS(X,y, lambda_reg=1.0):\n",
    "    X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Add bias term\n",
    "    n_features = X_b.shape[1]\n",
    "    \n",
    "    # Identity matrix for regularization (excluding bias term)\n",
    "    I = np.eye(n_features)\n",
    "    I[0, 0] = 0  # Do not regularize the bias term\n",
    "\n",
    "    # Compute theta using Ridge Regression\n",
    "    theta = np.linalg.inv(X_b.T.dot(X_b) + lambda_reg * I).dot(X_b.T).dot(y)\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.52629872e+00 -2.55410344e-02 -2.75464963e-03  7.97157096e-02\n",
      "  2.45430898e-01  2.30997001e-01  7.24669371e-02  8.35010508e-02\n",
      " -1.00313838e-03  1.07394367e-02 -6.23474500e-03 -5.56715733e-03\n",
      "  5.60266900e-02  3.58561163e-02  1.57574968e-03 -7.55549288e-03\n",
      "  3.69283931e-01  3.46783434e-02  7.95224273e-03  7.00266546e-02\n",
      "  4.24680913e-02 -6.29260584e-03 -1.07196052e-01  4.28761268e-02\n",
      "  2.42142441e-02 -1.44317175e-02  1.04464657e-01  1.78086256e-02\n",
      "  4.12002480e-03  1.95930455e-03  8.32172332e-04  4.92516249e-03\n",
      "  8.87905997e-03  1.49154179e-02 -4.98781256e-03  2.81330453e-03\n",
      " -2.65686568e-03 -2.94269257e-01  9.49750469e-02  8.14344546e-02\n",
      "  7.06046842e-02  4.72550716e-02 -4.59303379e-02  4.59303379e-02\n",
      " -9.70351428e-04  3.81879675e-02 -2.48914419e-04  1.71413453e-02\n",
      " -2.79198014e-02  1.10273706e-02 -3.20886294e-02  3.00942836e-02\n",
      " -1.26368445e-02  1.46311902e-02  8.49150844e-02 -8.49150843e-02\n",
      "  2.41116682e-02  4.63422104e-02 -2.60183460e-02 -5.44847325e-02\n",
      "  1.00492000e-02  7.66759888e-03  3.33649814e-02 -4.10325802e-02\n",
      "  3.05332048e-02 -5.96061604e-03 -1.04204711e-03 -8.15170290e-03\n",
      "  2.19787847e-02 -3.38431148e-03  8.63738469e-02 -1.03440960e-01\n",
      " -1.51695694e-02 -7.01516221e-02 -1.09512531e-01 -5.47528767e-02\n",
      " -4.83771605e-02  2.20711923e-02 -5.46463260e-02  1.10299977e-01\n",
      "  1.05573779e-01 -7.40372514e-02 -1.32761976e-02 -3.82820743e-02\n",
      " -5.90235423e-03  5.32526515e-02  1.50210208e-01  3.60138748e-03\n",
      "  2.21925693e-02 -3.85328234e-02 -1.36634575e-02  4.68935802e-02\n",
      "  3.14056113e-03  2.73329135e-02 -7.20035408e-02  1.50078862e-02\n",
      " -1.73752804e-02  4.92001612e-02  1.14215193e-02  8.85419150e-02\n",
      "  6.84473265e-02  1.06174073e-01 -3.18599768e-01 -3.78986359e-02\n",
      " -5.85755634e-03  8.77711263e-02  4.26838493e-03  3.67838250e-03\n",
      " -5.20471851e-03 -1.07283378e-02  7.98628871e-03 -2.12102144e-02\n",
      "  3.21879929e-02 -5.34057579e-03 -2.88326369e-02  1.09165154e-02\n",
      " -2.95060479e-02  2.93833164e-02  1.24016502e-02  3.10296753e-02\n",
      " -2.81035216e-02 -4.25242236e-02 -2.12839355e-02  7.77735952e-03\n",
      "  5.31046458e-02 -5.53000716e-01  8.85711680e-02  1.00855187e-01\n",
      "  3.23551314e-02  4.49757705e-02  1.46931377e-03  7.35959191e-02\n",
      "  2.11178227e-01  3.92670713e-02 -1.09447784e-02 -8.58331054e-02\n",
      "  8.10835527e-02 -5.26830657e-02 -6.02549303e-03  9.20682213e-04\n",
      " -1.27768701e-02  2.80149303e-02  1.39664872e-02  2.94666410e-03\n",
      "  1.48336120e-02  4.37997181e-03 -3.44628200e-02  1.73131611e-02\n",
      " -3.37877237e-02  3.23518467e-02 -1.06279351e-02 -2.23090185e-02\n",
      " -5.26830657e-02  4.80249534e-02  7.55329794e-03  3.28045427e-02\n",
      "  4.53944282e-03 -2.76915474e-02  3.37777836e-03 -3.51440888e-02\n",
      " -1.92445994e-02  3.66443157e-02  4.00061289e-02 -3.81432784e-03\n",
      " -2.34185070e-02  8.19200897e-03  2.19554779e-02 -1.68848512e-03\n",
      "  4.36071876e-02 -1.48157034e-02 -2.71029989e-02  9.09994634e-02\n",
      " -4.44592037e-02 -2.87543498e-02 -4.43200491e-03 -1.33539050e-02\n",
      " -3.57158171e-02  6.80523106e-03  1.84109674e-02  2.17770185e-02\n",
      "  5.33235736e-02 -6.46009735e-02  4.32070303e-03 -6.13418127e-02\n",
      " -5.30279431e-02 -6.79238210e-02 -8.74668065e-02 -6.14822330e-02\n",
      "  3.69428222e-02 -6.59666563e-02 -2.58188367e-02  1.61884411e-02\n",
      " -2.91288663e-02 -4.30024677e-02 -2.28591543e-02 -3.39622490e-02\n",
      " -1.16309086e-02 -6.27762997e-02 -4.10792769e-02 -5.66498512e-03\n",
      "  6.65028139e-03 -6.75821455e-02  1.81193813e-02 -4.48017836e-02\n",
      " -4.39881697e-02 -6.61485293e-02 -4.73555627e-03  1.34805501e-02\n",
      "  9.52587738e-02 -1.09375227e-01 -2.47546811e-02  3.01261406e-02\n",
      "  3.10994237e-02  5.24072884e-03  3.05013123e-03 -3.19869574e-02\n",
      " -7.40332638e-03 -2.96998101e-02  2.96998102e-02 -4.28029975e-03\n",
      "  8.36168977e-03 -4.23447114e-04 -3.92298838e-02 -1.32718982e-02\n",
      "  6.64658048e-02 -2.80533171e-02 -1.23026046e-02 -2.61098829e-02\n",
      "  4.97701221e-02 -1.42330761e-01  4.16993893e-02  2.59952199e-02\n",
      " -6.10885853e-03 -7.01294708e-02  1.01104359e-01  1.64448166e-02\n",
      " -1.01652498e-02  5.60952225e-03  1.91247467e-02  6.12906458e-03\n",
      " -5.33745896e-02  1.70759142e-02  9.86955293e-03  2.23229045e-02\n",
      " -2.04545362e-02  1.99687971e-02  5.34742612e-03 -2.04338390e-03\n",
      " -7.89599916e-03  1.29803399e-01 -6.83111848e-02  1.30654722e-02\n",
      " -4.15173227e-02 -3.76323203e-02 -5.17504770e-02 -2.21829196e-02\n",
      "  2.78434185e-02  1.97899769e-02  2.17080443e-02 -4.05762044e-03\n",
      " -1.46309467e-02  1.86885671e-02  1.21881644e-01 -2.42933649e-02\n",
      " -1.21339756e-01  1.49667449e-03 -2.87946460e-02  7.55658951e-04\n",
      " -2.14440969e-02  3.61015832e-02 -5.94477765e-02  1.91629475e-02\n",
      " -9.11669828e-03 -5.74619397e-02  1.54644039e-02  3.74914950e-02\n",
      "  7.33613115e-02 -5.15035418e-02 -3.95030955e-02  4.79558719e-02\n",
      "  3.66767258e-02 -6.24812312e-02 -4.39226788e-02  4.77638340e-02\n",
      "  3.75360010e-02 -2.86598316e-02  2.66794968e-02 -3.93968214e-02]\n"
     ]
    }
   ],
   "source": [
    "theta=OLS(X_train,y_train)\n",
    "print(theta)\n",
    "X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "y_pred = X_test_b.dot(theta)\n",
    "y_pred=np.exp(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id': test.index + 1461, 'SalePrice': y_pred})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Screenshot here: https://github.com/phuongwhuynh/NLP_Lab/blob/main/Lab67/hw1/sceenshot_hw1.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
