{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Build a language model based on n-grams using the Laplace smoothing method for the following models:\n",
    "- 1-gram\n",
    "- 2-gram\n",
    "- 3-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries: nltk, gdown,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import sent_tokenize, TreebankWordTokenizer\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "import math\n",
    "import gdown\n",
    "nltk.download('punkt')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use gdown to download tedtalk.txt from the google drive link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?export=download&id=1tQ9zW0ihL3Uc6GIge9AIV1pQnHYI7ihI\n",
      "To: c:\\HCMUT\\Study\\HK242\\NLP\\Exercise\\Lab2\\Inclass\\tedtalk.txt\n",
      "100%|██████████| 40.3M/40.3M [00:01<00:00, 35.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tedtalk.txt'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=f\"https://drive.google.com/uc?export=download&id=1tQ9zW0ihL3Uc6GIge9AIV1pQnHYI7ihI\"\n",
    "output_path=\"tedtalk.txt\"\n",
    "gdown.download(url,output_path, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the plain text file and read into `corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text corpus from file\n",
    "with open('tedtalk.txt', 'r', encoding='utf-8') as file:\n",
    "    corpus = file.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the text by lowering, and keeping only `[a-z0-9 .!?\\']`.\n",
    "Then use `nltk.sent_tokenize()` to tokenize text into list of sentences and tokenize each sentence into list of words using `nltk.tokenize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text: lowercase, remove punctuation, tokenize\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    cleaned_text = re.sub(r\"[^a-z0-9 .!?\\']\", \" \", text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def split_sentences_and_tokenize(text):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    sentences = sent_tokenize(text)\n",
    "    tokenized_sentences = [tokenizer.tokenize(sentence) for sentence in sentences]\n",
    "    \n",
    "    return tokenized_sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate ngrams from sentences. Add `<s>` and `</s>` for 2-gram and 3-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate n-grams\n",
    "def generate_ngrams_from_sentences(sentences, n):\n",
    "    ngrams_list = []\n",
    "    for sentence in sentences:\n",
    "        padded_sentence=sentence\n",
    "        if n>1:\n",
    "            padded_sentence = ['<s>'] * (n - 1) + padded_sentence + ['</s>'] \n",
    "        ngrams_list.extend(list(ngrams(padded_sentence, n)))\n",
    "    return ngrams_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to precompute ngram probablity to optimize runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to compute n-gram probabilities with Laplace smoothing\n",
    "def compute_ngram_probs(vocabulary_size,token_size, n,ngram_counts,n_1_gram_counts, alpha=1):\n",
    "    probs = {}\n",
    "    \n",
    "    for ngram, count in ngram_counts.items():\n",
    "        if n == 1:  # For unigrams, no need for prefix_count\n",
    "            prefix_count = token_size \n",
    "        else:  # For bigrams or trigrams, use the prefix\n",
    "            prefix = ngram[:-1]  \n",
    "            prefix_count = n_1_gram_counts.get(prefix, 0)\n",
    "        # Apply Laplace smoothing\n",
    "        probs[ngram] = (count + alpha) / (prefix_count + alpha * vocabulary_size)\n",
    "    \n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess and tokenize based on sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['thank', 'you', 'so', 'much', 'chris', '.'], ['and', 'it', \"'s\", 'truly', 'a', 'great', 'honor', 'to', 'have', 'the', 'opportunity', 'to', 'come', 'to', 'this', 'stage', 'twice', 'i', \"'m\", 'extremely', 'grateful', '.'], ['i', 'have', 'been', 'blown', 'away', 'by', 'this', 'conference', 'and', 'i', 'want', 'to', 'thank', 'all', 'of', 'you', 'for', 'the', 'many', 'nice', 'comments', 'about', 'what', 'i', 'had', 'to', 'say', 'the', 'other', 'night', '.'], ['and', 'i', 'say', 'that', 'sincerely', 'partly', 'because', 'mock', 'sob', 'i', 'need', 'that', '.'], ['laughter', 'put', 'yourselves', 'in', 'my', 'position', '.'], ['laughter', 'i', 'flew', 'on', 'air', 'force', 'two', 'for', 'eight', 'years', '.'], ['laughter', 'now', 'i', 'have', 'to', 'take', 'off', 'my', 'shoes', 'or', 'boots', 'to', 'get', 'on', 'an', 'airplane', '!'], ['laughter', 'applause', 'i', \"'ll\", 'tell', 'you', 'one', 'quick', 'story', 'to', 'illustrate', 'what', 'that', \"'s\", 'been', 'like', 'for', 'me', '.'], ['laughter', 'it', \"'s\", 'a', 'true', 'story', 'every', 'bit', 'of', 'this', 'is', 'true', '.'], ['soon', 'after', 'tipper', 'and', 'i', 'left', 'the', 'mock', 'sob', 'white', 'house', 'laughter', 'we', 'were', 'driving', 'from', 'our', 'home', 'in', 'nashville', 'to', 'a', 'little', 'farm', 'we', 'have', '50', 'miles', 'east', 'of', 'nashville', '.'], ['driving', 'ourselves', '.'], ['laughter', 'i', 'know', 'it', 'sounds', 'like', 'a', 'little', 'thing', 'to', 'you', 'but', 'laughter', 'i', 'looked', 'in', 'the', 'rear', 'view', 'mirror', 'and', 'all', 'of', 'a', 'sudden', 'it', 'just', 'hit', 'me', '.'], ['there', 'was', 'no', 'motorcade', 'back', 'there', '.'], ['laughter', 'you', \"'ve\", 'heard', 'of', 'phantom', 'limb', 'pain', '?'], ['laughter', 'this', 'was', 'a', 'rented', 'ford', 'taurus', '.'], ['laughter', 'it', 'was', 'dinnertime', 'and', 'we', 'started', 'looking', 'for', 'a', 'place', 'to', 'eat', '.'], ['we', 'were', 'on', 'i', '40.', 'we', 'got', 'to', 'exit', '238', 'lebanon', 'tennessee', '.'], ['we', 'got', 'off', 'the', 'exit', 'we', 'found', 'a', 'shoney', \"'s\", 'restaurant', '.'], ['low', 'cost', 'family', 'restaurant', 'chain', 'for', 'those', 'of', 'you', 'who', 'do', \"n't\", 'know', 'it', '.'], ['we', 'went', 'in', 'and', 'sat', 'down', 'at', 'the', 'booth', 'and', 'the', 'waitress', 'came', 'over', 'made', 'a', 'big', 'commotion', 'over', 'tipper', '.']]\n"
     ]
    }
   ],
   "source": [
    "sentences=preprocess(corpus)\n",
    "sentences = split_sentences_and_tokenize(sentences)\n",
    "print(sentences[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total number of tokens, calculate the vocabulary size, count unigram, bigram, trigram and use them to precompute the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens:  7835609\n",
      "Vocabulary size:  69944\n"
     ]
    }
   ],
   "source": [
    "all_tokens = [token for sentence in sentences for token in sentence]\n",
    "vocabulary_size = len(set(all_tokens))  \n",
    "token_size=len(all_tokens)\n",
    "print(\"Total tokens: \",token_size)\n",
    "print(\"Vocabulary size: \", vocabulary_size)\n",
    "unigram_counts = Counter(generate_ngrams_from_sentences(sentences, 1))\n",
    "bigram_counts = Counter(generate_ngrams_from_sentences(sentences, 2)) \n",
    "trigram_counts = Counter(generate_ngrams_from_sentences(sentences, 3)) \n",
    "\n",
    "unigram_probs = compute_ngram_probs(vocabulary_size,token_size,1,unigram_counts,None)\n",
    "bigram_probs = compute_ngram_probs(vocabulary_size,token_size,2,bigram_counts,unigram_counts)\n",
    "trigram_probs = compute_ngram_probs(vocabulary_size,token_size,3,trigram_counts,bigram_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Unigram Count: [(('thank',), 5195), (('you',), 108403), (('so',), 57089), (('much',), 9220), (('chris',), 498), (('.',), 400768), (('and',), 240579), (('it',), 115807), ((\"'s\",), 85344), (('truly',), 695), (('a',), 170846), (('great',), 4756), (('honor',), 277), (('to',), 210927), (('have',), 44958), (('the',), 336385), (('opportunity',), 1156), (('come',), 6146), (('this',), 74906), (('stage',), 952)]\n",
      "Sample Bigram Count: [(('<s>', 'thank'), 3222), (('thank', 'you'), 5001), (('you', 'so'), 356), (('so', 'much'), 1751), (('much', 'chris'), 4), (('chris', '.'), 56), (('.', '</s>'), 400542), (('<s>', 'and'), 60110), (('and', 'it'), 8960), (('it', \"'s\"), 32904), ((\"'s\", 'truly'), 25), (('truly', 'a'), 20), (('a', 'great'), 1219), (('great', 'honor'), 17), (('honor', 'to'), 27)]\n",
      "Sample Trigram Count: [(('<s>', '<s>', 'thank'), 3222), (('<s>', 'thank', 'you'), 3194), (('thank', 'you', 'so'), 259), (('you', 'so', 'much'), 261), (('so', 'much', 'chris'), 3), (('much', 'chris', '.'), 4), (('chris', '.', '</s>'), 56), (('<s>', '<s>', 'and'), 60110), (('<s>', 'and', 'it'), 3260), (('and', 'it', \"'s\"), 3590), (('it', \"'s\", 'truly'), 14), ((\"'s\", 'truly', 'a'), 4), (('truly', 'a', 'great'), 1), (('a', 'great', 'honor'), 9), (('great', 'honor', 'to'), 8)]\n",
      "Sample Unigram Probabilities: [(('thank',), 0.0006572595237803099), (('you',), 0.013712386723610607), (('so',), 0.007221506199503058), (('much',), 0.0011663953173168277), (('chris',), 6.312018906204284e-05), (('.',), 0.05069461933908988), (('and',), 0.030431773716525588), (('it',), 0.014648943596988092), ((\"'s\",), 0.010795576223446988), (('truly',), 8.803938193824012e-05), (('a',), 0.02161101190517602), (('great',), 0.0006017289366094947), (('honor',), 3.516515542935453e-05), (('to',), 0.02668099246188091), (('have',), 0.005687015190461692)]\n",
      "Sample Bigram Probabilities: [(('<s>', 'thank'), 0.046079720919592816), (('thank', 'you'), 0.06656995701300257), (('you', 'so'), 0.0020017157563625965), (('so', 'much'), 0.0137916919225713), (('much', 'chris'), 6.316002223232782e-05), (('chris', '.'), 0.0008091763436586127), (('.', '</s>'), 0.8509300803888578), (('<s>', 'and'), 0.8594161043120211), (('and', 'it'), 0.0288577657693633), (('it', \"'s\"), 0.1771457488788755), ((\"'s\", 'truly'), 0.00016743083818453454), (('truly', 'a'), 0.0002972862016732966), (('a', 'great'), 0.005066655592009635), (('great', 'honor'), 0.00024096385542168674), (('honor', 'to'), 0.0003987411173295738)]\n",
      "Sample Trigram Probabilities: [(('<s>', '<s>', 'thank'), 0.046079720919592816), (('<s>', 'thank', 'you'), 0.04366782385260914), (('thank', 'you', 'so'), 0.003469210754553339), (('you', 'so', 'much'), 0.0037268847795163583), (('so', 'much', 'chris'), 5.579189622707302e-05), (('much', 'chris', '.'), 7.148167209927375e-05), (('chris', '.', '</s>'), 0.0008142857142857143), (('<s>', '<s>', 'and'), 0.8594161043120211), (('<s>', 'and', 'it'), 0.025074199947714027), (('and', 'it', \"'s\"), 0.04551100070972321), (('it', \"'s\", 'truly'), 0.0001458462974486621), ((\"'s\", 'truly', 'a'), 7.146021809658563e-05), (('truly', 'a', 'great'), 2.8586130009719286e-05), (('a', 'great', 'honor'), 0.00014052246251563313), (('great', 'honor', 'to'), 0.00012864310115635855)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Unigram Count:\", list(unigram_counts.items())[:20])\n",
    "print(\"Sample Bigram Count:\", list(bigram_counts.items())[:15])\n",
    "print(\"Sample Trigram Count:\", list(trigram_counts.items())[:15])\n",
    "\n",
    "print(\"Sample Unigram Probabilities:\", list(unigram_probs.items())[:15])\n",
    "print(\"Sample Bigram Probabilities:\", list(bigram_probs.items())[:15])\n",
    "print(\"Sample Trigram Probabilities:\", list(trigram_probs.items())[:15])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate probability of a sentence, fall back to computing again using ngram counts if the precomputation is not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentence_probability(sentence, ngram_probs,n_1gram_count,token_size,vocabulary_size, n, alpha=1):\n",
    "    tokens = [word for sentence in split_sentences_and_tokenize(preprocess(sentence)) for word in sentence]\n",
    "    prob = 1.0\n",
    "\n",
    "    if n > 1:\n",
    "        tokens = ['<s>'] * (n - 1) + tokens + ['</s>']  # Add boundary tokens for bigram/trigram\n",
    "\n",
    "    # Calculate the probability using precomputed smoothed n-gram probabilities\n",
    "    for i in range(n - 1, len(tokens)):  \n",
    "        ngram = tuple(tokens[i - n + 1:i + 1])  \n",
    "        prob_word = ngram_probs.get(ngram, 0)  \n",
    "        # Apply Laplace smoothing if the n-gram is unseen\n",
    "        if prob_word == 0:  \n",
    "            if n!=1:\n",
    "                prefix = ngram[:-1]  \n",
    "                prefix_count = n_1gram_count.get(prefix, 0)  \n",
    "            else:\n",
    "                prefix_count=token_size\n",
    "            prob_word = (alpha) / (prefix_count + alpha * vocabulary_size)\n",
    "        prob *= prob_word\n",
    "\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate perplexity of a sentence, fall back to computing again using ngram counts if the precomputation is not found. The perplexity is calculated using logarith instead of inverse to avoid underflowing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(sentence, ngram_probs,n_1gram_count,token_size,vocabulary_size, n, alpha=1):\n",
    "    tokens = [word for sentence in split_sentences_and_tokenize(preprocess(sentence)) for word in sentence]\n",
    "    if n > 1:\n",
    "        tokens = ['<s>'] * (n - 1) + tokens + ['</s>']  # Add boundary tokens for bigram/trigram\n",
    "    total_log_prob = 0.0\n",
    "    for i in range(n - 1, len(tokens)):  \n",
    "        ngram = tuple(tokens[i - n + 1:i + 1])  \n",
    "        prob_word = ngram_probs.get(ngram, 0)  \n",
    "        \n",
    "        # Apply Laplace smoothing if the n-gram is unseen\n",
    "        if prob_word == 0:\n",
    "            if n!=1:\n",
    "                prefix = ngram[:-1]  # Prefix is the first (n-1) tokens\n",
    "                prefix_count = n_1gram_count.get(prefix, 0)  # Get prefix count (smoothed)\n",
    "            else:\n",
    "                prefix_count=token_size\n",
    "            prob_word = (alpha) / (prefix_count + alpha * vocabulary_size)\n",
    "        # Perplexity calculation using logarith instead of inverse\n",
    "        total_log_prob += math.log(prob_word) if prob_word > 0 else float('-inf')\n",
    "\n",
    "    perplexity = math.exp(-total_log_prob / (len(tokens)+1-n)) if total_log_prob > float('-inf') else float('inf')\n",
    "    return perplexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Calculate the probability of a sentence and compute the Perplexity of a sentence based on 1-gram, 2-gram, and 3-gram models.\n",
    "\n",
    "The sentence chosen is \"I want to speak at ted talk.\" This will be the base sentence to compare below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Probability: 1.5121885066224436e-21\n",
      "Bigram Probability: 4.873652655324646e-18\n",
      "Trigram Probability: 3.169912235179167e-26\n",
      "Unigram Perplexity: 400.45088554805614\n",
      "Bigram Perplexity: 83.86325485941741\n",
      "Trigram Perplexity: 681.1095560648001\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I want to speak at ted talk.\"\n",
    "unigram_prob = calculate_sentence_probability(sentence, unigram_probs, None,token_size, vocabulary_size, 1)\n",
    "bigram_prob = calculate_sentence_probability(sentence, bigram_probs,unigram_counts,token_size, vocabulary_size, 2)\n",
    "trigram_prob = calculate_sentence_probability(sentence, trigram_probs,bigram_counts,token_size, vocabulary_size, 3)\n",
    "\n",
    "print(\"Unigram Probability:\", unigram_prob)\n",
    "print(\"Bigram Probability:\", bigram_prob)\n",
    "print(\"Trigram Probability:\", trigram_prob)\n",
    "\n",
    "print(\"Unigram Perplexity:\", calculate_perplexity(sentence, unigram_probs, None,token_size, vocabulary_size, 1))\n",
    "print(\"Bigram Perplexity:\", calculate_perplexity(sentence, bigram_probs,unigram_counts,token_size, vocabulary_size, 2))\n",
    "print(\"Trigram Perplexity:\", calculate_perplexity(sentence, trigram_probs,bigram_counts,token_size, vocabulary_size, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Analyze the results (Provide your own examples of spelling errors and calculate the probability of two similar sentences, where one has the correct word order and the other has an incorrect word order).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of spelling errors of the previous sentence, the perplexity is much higher indicating this sentence does not fit with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Probability: 9.250038516821093e-26\n",
      "Bigram Probability: 5.691648843830339e-30\n",
      "Trigram Probability: 1.6917893350584108e-35\n",
      "Unigram Perplexity: 1346.5796822248376\n",
      "Bigram Perplexity: 1775.8978814480727\n",
      "Trigram Perplexity: 7303.265341672125\n"
     ]
    }
   ],
   "source": [
    "#Example of spelling errors\n",
    "sentence = \"I went too speak ate ted take.\"\n",
    "unigram_prob = calculate_sentence_probability(sentence, unigram_probs, None,token_size, vocabulary_size, 1)\n",
    "bigram_prob = calculate_sentence_probability(sentence, bigram_probs,unigram_counts,token_size, vocabulary_size, 2)\n",
    "trigram_prob = calculate_sentence_probability(sentence, trigram_probs,bigram_counts,token_size, vocabulary_size, 3)\n",
    "\n",
    "print(\"Unigram Probability:\", unigram_prob)\n",
    "print(\"Bigram Probability:\", bigram_prob)\n",
    "print(\"Trigram Probability:\", trigram_prob)\n",
    "\n",
    "print(\"Unigram Perplexity:\", calculate_perplexity(sentence, unigram_probs, None,token_size, vocabulary_size, 1))\n",
    "print(\"Bigram Perplexity:\", calculate_perplexity(sentence, bigram_probs,unigram_counts,token_size, vocabulary_size, 2))\n",
    "print(\"Trigram Perplexity:\", calculate_perplexity(sentence, trigram_probs,bigram_counts,token_size, vocabulary_size, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of wrong order of the above sentence, the perplexity is higher on all 2gram and 3gram models compared with the base sentence but is not as high as the spelling error sentence. This sentence is worse than the base sentence but is better than the spelling error one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Probability: 1.5121885066224436e-21\n",
      "Bigram Probability: 8.419420677427076e-23\n",
      "Trigram Probability: 1.2948934335583005e-34\n",
      "Unigram Perplexity: 400.45088554805614\n",
      "Bigram Perplexity: 283.62624884244127\n",
      "Trigram Perplexity: 5825.152911373741\n"
     ]
    }
   ],
   "source": [
    "#Example of spelling errors\n",
    "sentence = \"I speak at want to ted talk.\"\n",
    "unigram_prob = calculate_sentence_probability(sentence, unigram_probs, None,token_size, vocabulary_size, 1)\n",
    "bigram_prob = calculate_sentence_probability(sentence, bigram_probs,unigram_counts,token_size, vocabulary_size, 2)\n",
    "trigram_prob = calculate_sentence_probability(sentence, trigram_probs,bigram_counts,token_size, vocabulary_size, 3)\n",
    "\n",
    "print(\"Unigram Probability:\", unigram_prob)\n",
    "print(\"Bigram Probability:\", bigram_prob)\n",
    "print(\"Trigram Probability:\", trigram_prob)\n",
    "\n",
    "print(\"Unigram Perplexity:\", calculate_perplexity(sentence, unigram_probs, None,token_size, vocabulary_size, 1))\n",
    "print(\"Bigram Perplexity:\", calculate_perplexity(sentence, bigram_probs,unigram_counts,token_size, vocabulary_size, 2))\n",
    "print(\"Trigram Perplexity:\", calculate_perplexity(sentence, trigram_probs,bigram_counts,token_size, vocabulary_size, 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
